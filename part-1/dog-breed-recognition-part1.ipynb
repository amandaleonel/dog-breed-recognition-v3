{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import math\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torch\nfrom copy import copy\nfrom glob import glob\nfrom PIL import Image, ImageFile\nfrom torch import nn\nfrom torch import optim\nfrom torch.autograd import Variable\nfrom torch.utils.data import random_split, DataLoader\nfrom torchvision import datasets, transforms, models\nfrom tqdm import tqdm\nimport recgn_utils # utility script ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Verifica se CUDA está disponível \ngpu_on = torch.cuda.is_available()\n\nif not gpu_on:\n    print('Use a CPU. CUDA não está disponível...')\nelse:\n    print('Use a GPU. CUDA está disponível...')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Configure alguns parametros:\n\n# Path raiz do dataset \ndogs_dir = '../input/dog-breed-recognition-v3/dogs/'\n\n# Tamanho do dataset\nbatch_size = 32\n\n# Numero de workers\nnum_workers = 0\n\n# Numero de epocas\nnum_epochs = 20","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Carrega o dataset usando ImageFolder\ndata_dir = dogs_dir + 'train'\nclass_names = [item.split('/')[-2] for item in sorted(glob(data_dir + \"/*/\"))]\n\n# Plota quantidade ordenada de imagens por classe, para verficar se estao desbalanceadas\n_, _ = recgn_utils.check_class(data_dir)\n\n# Calcula numero de classes\nnum_classes = len(class_names)\n\n# Cria dataset de imagens     \nds_train = datasets.ImageFolder(data_dir)\n\n# Calcula total de imagens\ntotal_img = len(ds_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define tamanho dos datasets, multiplos do batch qunado possivel\ntrain_size = math.ceil(total_img*0.8/batch_size) * batch_size\nvalid_size = math.ceil(total_img*0.1/batch_size) * batch_size\ntest_size = total_img - (train_size + valid_size)\n\n# Divide dataset em datasets disjuntos de treinamento, validação e teste\ntrain_set, val_set, test_set = random_split(ds_train, [train_size, valid_size, test_size],\n                                            torch.Generator().manual_seed(2147483647))\n\nprint(f'Numero de classes: {num_classes}')\nprint(f'Numero de imagens de treinamento: {len(train_set)}')\nprint(f'Numero de imagens de validacao: {len(val_set)}')\nprint(f'Numero de imagens de testes: {len(test_set)}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define valores mean e std para normalizar as imagens\n# TODO: Valores baseados no ImageNet. Idealmente calcular o mean e std do dataset original\nimg_mean = np.array((0.485, 0.456, 0.406))\nimg_std = np.array((0.229, 0.224, 0.225))\n\n# Define e aplica transformações nos datasets de treinamento, validação e teste\ntrain_set.dataset = copy(ds_train)\ntrain_set.dataset.transform = transforms.Compose([\n                                    transforms.RandomHorizontalFlip(),\n                                    transforms.RandomRotation(10),\n                                    transforms.Resize((224, 224)),\n                                    transforms.ToTensor(),\n                                    transforms.Normalize(img_mean, \n                                                         img_std)])\nval_set.dataset.transform = transforms.Compose([transforms.CenterCrop(224),\n                                    transforms.ToTensor(),\n                                    transforms.Normalize(img_mean, \n                                                         img_std)])\ntest_set.dataset.transform = transforms.Compose([transforms.CenterCrop(224),\n                                    transforms.ToTensor(),\n                                    transforms.Normalize(img_mean, \n                                                         img_std)])\n# Cria conjunto de loaders\ntrain_loader = DataLoader(train_set, batch_size=batch_size, num_workers=num_workers, shuffle=True)\nvalid_loader = DataLoader(val_set, batch_size=batch_size, num_workers=num_workers, shuffle=True)\ntest_loader = DataLoader(test_set, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n\nloaders = {'train': train_loader, 'valid': valid_loader, 'test': test_loader}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Exibe algumas imagens do loader com correspondentes labels\n\nmeanm = np.mean(img_mean)\nstdm = np.mean(img_std)        \nrecgn_utils.sample_img_show(train_loader, class_names, meanm, stdm)        ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Configuração do Transfer Learning\n\n# Seleciona modelo pre-treinado\n# https://pytorch.org/hub/pytorch_vision_resnet/\nmodel = models.resnet152(pretrained=True)\nprint(f'Camada fully connected da ResNet152: \\n{model.fc}')\n\n# Descongela camadas para treinamento (fine-tunning)\nfor param in model.parameters():\n    param.requires_grad = True\n    \n# Redefine camada fully connected\nmodel.fc = nn.Sequential(nn.Linear(model.fc.in_features, 512),\n                                  nn.ReLU(),\n                                  nn.Linear(512, 256),\n                                  nn.ReLU(),\n                                  nn.Dropout(0.5),\n                                  nn.Linear(256, num_classes),\n                                  nn.LogSoftmax(dim=1)) \nprint(f'\\nNovo classificador: \\n{model.fc}')\n\n# Define loss function (categorical cross-entropy)\n# https://pytorch.org/docs/stable/generated/torch.nn.NLLLoss.html\ncriterion = nn.NLLLoss()\n\n# Define otimizador de treinamento e diferentes taxas de aprendizado ao longo da rede\n# https://pytorch.org/docs/stable/generated/torch.optim.SGD.html\nignored_params = list(map(id, model.fc.parameters()))\nbase_params = filter(lambda p: id(p) not in ignored_params,\n                     model.parameters())\noptimizer = torch.optim.SGD([\n            {'params': base_params},\n            {'params': model.fc.parameters(), 'lr': 0.001}\n        ], lr=0.0001, momentum=0.9)\n\nif gpu_on:\n    model.cuda()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Treina modelo \n\n# Considera condicoes de parada:\n# 1) Valid loss medio crescente\n# 2) Numero de epocas = num_epochs\n\nmodel = recgn_utils.train_model(model, criterion, optimizer, loaders, num_epochs, \n                                gpu_on)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Testa modelo treinado com loader de testes\n\nprob_pass, prob_fail = recgn_utils.test_model(model, criterion, test_loader, gpu_on)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plota distribuição de probabilidades nos cassos de pass e fail do teste   \n\nplt.hist(prob_fail, bins = np.arange(0,1.05,0.05)) \nplt.hist(prob_pass, bins = np.arange(0,1.05,0.05), alpha = 0.7) \nlabels= [\"Fail\",\"Pass\"]\nplt.legend(labels)\nplt.xlabel('Probability')\nplt.ylabel('Frequency')\nplt.title('Max outputs')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Seleciona uma foto aleatoria e verifica saida do modelo\n\ntrain_dir = '../input/dog-breed-recognition-v3/dogs/train/*/*'\nenroll_data = np.array(glob(train_dir))\nimg_path = np.random.choice(enroll_data, 1)[0]\nrecgn_utils.imshow(img_path)\nprint(f'Foto selecionada aleatoriamente em:{img_path}')\npred_breed, pred_prob = recgn_utils.predict_breed_dog(model, class_names, img_mean, img_std, img_path, gpu_on)\nprint(f'Probabilidade de {pred_prob*100:.2f}% de ser um {pred_breed}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}